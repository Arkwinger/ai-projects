#  Red Teaming AI — Practical Attacks (HTB Module)

This project demonstrates three real-world attacks against machine learning systems:

- **ML01 – Input Manipulation**
- **ML02 – Data Poisoning**
- **ML05 – Model Theft**

These attacks align with the **OWASP Top 10 for Machine Learning Security** and were performed through hands-on labs.

The purpose of this project is to show how **ML systems can be exploited without hacking the server directly** — instead, by attacking the *model itself*, its training data, or its exposed endpoints.

---
